{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:53.713252Z",
     "iopub.status.busy": "2023-08-28T14:16:53.712812Z",
     "iopub.status.idle": "2023-08-28T14:16:53.769868Z",
     "shell.execute_reply": "2023-08-28T14:16:53.768850Z",
     "shell.execute_reply.started": "2023-08-28T14:16:53.713212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fra-eng/fra.txt\n",
      "/kaggle/input/hin-eng/hin.txt\n",
      "/kaggle/input/hindi-eng/hindi_english_parallel.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:53.772244Z",
     "iopub.status.busy": "2023-08-28T14:16:53.771903Z",
     "iopub.status.idle": "2023-08-28T14:16:54.847361Z",
     "shell.execute_reply": "2023-08-28T14:16:54.845068Z",
     "shell.execute_reply.started": "2023-08-28T14:16:53.772210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29/3470684711.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  lines= pd.read_table('/kaggle/input/fra-eng/fra.txt', names=['eng', 'fra'],index_col=False,nrows = 200000)\n"
     ]
    }
   ],
   "source": [
    "lines= pd.read_table('/kaggle/input/fra-eng/fra.txt', names=['eng', 'fra'],index_col=False,nrows = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:54.849463Z",
     "iopub.status.busy": "2023-08-28T14:16:54.849109Z",
     "iopub.status.idle": "2023-08-28T14:16:54.865565Z",
     "shell.execute_reply": "2023-08-28T14:16:54.864403Z",
     "shell.execute_reply.started": "2023-08-28T14:16:54.849428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    Go.\n",
       " 1    Go.\n",
       " 2    Go.\n",
       " 3    Go.\n",
       " 4    Hi.\n",
       " Name: eng, dtype: object,\n",
       " 0          Va !\n",
       " 1       Marche.\n",
       " 2    En route !\n",
       " 3       Bouge !\n",
       " 4       Salut !\n",
       " Name: fra, dtype: object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng[:5],lines.fra[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:54.869706Z",
     "iopub.status.busy": "2023-08-28T14:16:54.868700Z",
     "iopub.status.idle": "2023-08-28T14:16:54.877310Z",
     "shell.execute_reply": "2023-08-28T14:16:54.875878Z",
     "shell.execute_reply.started": "2023-08-28T14:16:54.869671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:54.879264Z",
     "iopub.status.busy": "2023-08-28T14:16:54.878907Z",
     "iopub.status.idle": "2023-08-28T14:16:57.257274Z",
     "shell.execute_reply": "2023-08-28T14:16:57.256204Z",
     "shell.execute_reply.started": "2023-08-28T14:16:54.879231Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "lines.eng = lines.eng.apply(lambda x:x.lower())\n",
    "lines.fra = lines.fra.apply(lambda x:x.lower())\n",
    "punctuation = set(string.punctuation)\n",
    "lines.eng = lines.eng.apply(lambda x:''.join(char for char in x if char not in punctuation))\n",
    "lines.fra = lines.fra.apply(lambda x:''.join(char for char in x if char not in punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:57.259191Z",
     "iopub.status.busy": "2023-08-28T14:16:57.258720Z",
     "iopub.status.idle": "2023-08-28T14:16:57.268814Z",
     "shell.execute_reply": "2023-08-28T14:16:57.267779Z",
     "shell.execute_reply.started": "2023-08-28T14:16:57.259148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('what a fiasco', 'quel échec\\xa0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng[10000],lines.fra[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:57.273405Z",
     "iopub.status.busy": "2023-08-28T14:16:57.272852Z",
     "iopub.status.idle": "2023-08-28T14:16:59.111302Z",
     "shell.execute_reply": "2023-08-28T14:16:59.110155Z",
     "shell.execute_reply.started": "2023-08-28T14:16:57.273349Z"
    }
   },
   "outputs": [],
   "source": [
    "digits = set(string.digits)\n",
    "lines.eng = lines.eng.apply(lambda x:''.join(char for char in x if char not in digits))\n",
    "lines.fra = lines.fra.apply(lambda x:''.join(char for char in x if char not in digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:16:59.113327Z",
     "iopub.status.busy": "2023-08-28T14:16:59.112947Z",
     "iopub.status.idle": "2023-08-28T14:17:00.803958Z",
     "shell.execute_reply": "2023-08-28T14:17:00.802810Z",
     "shell.execute_reply.started": "2023-08-28T14:16:59.113287Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.fra=lines.fra.apply(lambda x: x.strip())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.fra=lines.fra.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:00.806173Z",
     "iopub.status.busy": "2023-08-28T14:17:00.805404Z",
     "iopub.status.idle": "2023-08-28T14:17:00.918095Z",
     "shell.execute_reply": "2023-08-28T14:17:00.916991Z",
     "shell.execute_reply.started": "2023-08-28T14:17:00.806131Z"
    }
   },
   "outputs": [],
   "source": [
    "lines.fra = lines.fra.apply(lambda x : '<SOS> '+ x + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:00.923650Z",
     "iopub.status.busy": "2023-08-28T14:17:00.923291Z",
     "iopub.status.idle": "2023-08-28T14:17:00.933669Z",
     "shell.execute_reply": "2023-08-28T14:17:00.932451Z",
     "shell.execute_reply.started": "2023-08-28T14:17:00.923619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              <SOS> va <EOS>\n",
       "1                          <SOS> marche <EOS>\n",
       "2                        <SOS> en route <EOS>\n",
       "3                           <SOS> bouge <EOS>\n",
       "4                           <SOS> salut <EOS>\n",
       "5                           <SOS> salut <EOS>\n",
       "6                           <SOS> cours <EOS>\n",
       "7                          <SOS> courez <EOS>\n",
       "8    <SOS> prenez vos jambes à vos cous <EOS>\n",
       "9                            <SOS> file <EOS>\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.fra[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:00.936507Z",
     "iopub.status.busy": "2023-08-28T14:17:00.936030Z",
     "iopub.status.idle": "2023-08-28T14:17:01.467231Z",
     "shell.execute_reply": "2023-08-28T14:17:01.466160Z",
     "shell.execute_reply.started": "2023-08-28T14:17:00.936471Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:01.470228Z",
     "iopub.status.busy": "2023-08-28T14:17:01.469234Z",
     "iopub.status.idle": "2023-08-28T14:17:01.491224Z",
     "shell.execute_reply": "2023-08-28T14:17:01.490173Z",
     "shell.execute_reply.started": "2023-08-28T14:17:01.470191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92228</th>\n",
       "      <td>i will choose one of them</td>\n",
       "      <td>&lt;SOS&gt; je choisirai un de ceuxlà &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46472</th>\n",
       "      <td>can you make a salad</td>\n",
       "      <td>&lt;SOS&gt; peuxtu préparer une salade &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199763</th>\n",
       "      <td>you shouldnt let people use you like that</td>\n",
       "      <td>&lt;SOS&gt; tu ne devrais pas laisser les gens tutil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30980</th>\n",
       "      <td>why are you angry</td>\n",
       "      <td>&lt;SOS&gt; pourquoi estu en colère &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9145</th>\n",
       "      <td>symptoms vary</td>\n",
       "      <td>&lt;SOS&gt; les symptômes sont variables &lt;EOS&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              eng  \\\n",
       "92228                   i will choose one of them   \n",
       "46472                        can you make a salad   \n",
       "199763  you shouldnt let people use you like that   \n",
       "30980                           why are you angry   \n",
       "9145                                symptoms vary   \n",
       "\n",
       "                                                      fra  \n",
       "92228               <SOS> je choisirai un de ceuxlà <EOS>  \n",
       "46472              <SOS> peuxtu préparer une salade <EOS>  \n",
       "199763  <SOS> tu ne devrais pas laisser les gens tutil...  \n",
       "30980                 <SOS> pourquoi estu en colère <EOS>  \n",
       "9145             <SOS> les symptômes sont variables <EOS>  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's find total number of english and french words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:01.493140Z",
     "iopub.status.busy": "2023-08-28T14:17:01.492714Z",
     "iopub.status.idle": "2023-08-28T14:17:02.287994Z",
     "shell.execute_reply": "2023-08-28T14:17:02.286984Z",
     "shell.execute_reply.started": "2023-08-28T14:17:01.493105Z"
    }
   },
   "outputs": [],
   "source": [
    "english_words = set()\n",
    "for line in lines.eng:\n",
    "    for word in line.split():\n",
    "        if word not in english_words:\n",
    "            english_words.add(word)\n",
    "french_words = set()\n",
    "for line in lines.fra:\n",
    "    for word in line.split():\n",
    "        if word not in french_words:\n",
    "            french_words.add(word)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:02.290239Z",
     "iopub.status.busy": "2023-08-28T14:17:02.289477Z",
     "iopub.status.idle": "2023-08-28T14:17:02.299563Z",
     "shell.execute_reply": "2023-08-28T14:17:02.296348Z",
     "shell.execute_reply.started": "2023-08-28T14:17:02.290195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13720, 28302)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_english_words = len(english_words)\n",
    "total_french_words = len(french_words)\n",
    "total_english_words,total_french_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To find the maximum sentence length of english and french sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:02.302109Z",
     "iopub.status.busy": "2023-08-28T14:17:02.301410Z",
     "iopub.status.idle": "2023-08-28T14:17:02.520458Z",
     "shell.execute_reply": "2023-08-28T14:17:02.519372Z",
     "shell.execute_reply.started": "2023-08-28T14:17:02.302074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "eng_len = []\n",
    "for line in lines.eng:\n",
    "    eng_len.append(len(line.split()))\n",
    "max_english_sen_len = np.max(eng_len)\n",
    "max_english_sen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:02.523990Z",
     "iopub.status.busy": "2023-08-28T14:17:02.523666Z",
     "iopub.status.idle": "2023-08-28T14:17:02.792438Z",
     "shell.execute_reply": "2023-08-28T14:17:02.791371Z",
     "shell.execute_reply.started": "2023-08-28T14:17:02.523965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_len = []\n",
    "for line in lines.fra:\n",
    "    fra_len.append(len(line.split()))\n",
    "max_french_sen_len = np.max(fra_len)\n",
    "max_french_sen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:02.794320Z",
     "iopub.status.busy": "2023-08-28T14:17:02.793963Z",
     "iopub.status.idle": "2023-08-28T14:17:02.831917Z",
     "shell.execute_reply": "2023-08-28T14:17:02.831029Z",
     "shell.execute_reply.started": "2023-08-28T14:17:02.794291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13721, 28304)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(english_words))\n",
    "target_words = sorted(list(french_words))\n",
    "num_encoder_tokens = len(english_words)+1\n",
    "num_decoder_tokens = len(french_words)+1\n",
    "num_decoder_tokens+=1 #zero padding\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:02.834361Z",
     "iopub.status.busy": "2023-08-28T14:17:02.833940Z",
     "iopub.status.idle": "2023-08-28T14:17:03.088270Z",
     "shell.execute_reply": "2023-08-28T14:17:03.087287Z",
     "shell.execute_reply.started": "2023-08-28T14:17:02.834326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160000,), (40000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = lines.eng, lines.fra\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:03.090533Z",
     "iopub.status.busy": "2023-08-28T14:17:03.089698Z",
     "iopub.status.idle": "2023-08-28T14:17:03.116619Z",
     "shell.execute_reply": "2023-08-28T14:17:03.115639Z",
     "shell.execute_reply.started": "2023-08-28T14:17:03.090496Z"
    }
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:03.118830Z",
     "iopub.status.busy": "2023-08-28T14:17:03.118224Z",
     "iopub.status.idle": "2023-08-28T14:17:03.135780Z",
     "shell.execute_reply": "2023-08-28T14:17:03.134596Z",
     "shell.execute_reply.started": "2023-08-28T14:17:03.118794Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Seq2Seq model(encoder and decoder)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:03.138791Z",
     "iopub.status.busy": "2023-08-28T14:17:03.138263Z",
     "iopub.status.idle": "2023-08-28T14:17:16.931057Z",
     "shell.execute_reply": "2023-08-28T14:17:16.930065Z",
     "shell.execute_reply.started": "2023-08-28T14:17:03.138724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,LSTM,Embedding,Input,Bidirectional,Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:16.934602Z",
     "iopub.status.busy": "2023-08-28T14:17:16.933459Z",
     "iopub.status.idle": "2023-08-28T14:17:16.939066Z",
     "shell.execute_reply": "2023-08-28T14:17:16.938101Z",
     "shell.execute_reply.started": "2023-08-28T14:17:16.934553Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:16.941546Z",
     "iopub.status.busy": "2023-08-28T14:17:16.940536Z",
     "iopub.status.idle": "2023-08-28T14:17:17.787405Z",
     "shell.execute_reply": "2023-08-28T14:17:17.786379Z",
     "shell.execute_reply.started": "2023-08-28T14:17:16.941510Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2, min_delta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:17.789680Z",
     "iopub.status.busy": "2023-08-28T14:17:17.789292Z",
     "iopub.status.idle": "2023-08-28T14:17:17.820524Z",
     "shell.execute_reply": "2023-08-28T14:17:17.819375Z",
     "shell.execute_reply.started": "2023-08-28T14:17:17.789645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Encoder Input Batch:\n",
      "[[ 5981.  7067.  4843. ...     0.     0.     0.]\n",
      " [12148.  8436.  8117. ...     0.     0.     0.]\n",
      " [ 4167.  7071. 12726. ...     0.     0.     0.]\n",
      " ...\n",
      " [12454.  6957. 13561. ...     0.     0.     0.]\n",
      " [ 3571. 13681.  5584. ...     0.     0.     0.]\n",
      " [ 3587.   500.  5584. ...     0.     0.     0.]]\n",
      "Decoder Input Batch:\n",
      "[[2.0000e+00 1.2662e+04 1.5461e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 3.3400e+03 1.8768e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 2.5978e+04 1.3659e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [2.0000e+00 1.3799e+04 9.8490e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 6.7030e+03 8.4000e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 9.2310e+03 2.0474e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]]\n",
      "Decoder Target Batch:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "------------------------------\n",
      "(128, 12) (128, 22) (128, 22, 28304)\n",
      "Batch 2:\n",
      "Encoder Input Batch:\n",
      "[[1.3283e+04 7.0990e+03 3.8120e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.2360e+04 1.2380e+04 1.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [3.6150e+03 1.0390e+03 4.9040e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [1.1950e+04 1.2335e+04 7.7780e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [1.2181e+04 1.5520e+03 8.2740e+03 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [3.6150e+03 6.8500e+03 1.2156e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]]\n",
      "Decoder Input Batch:\n",
      "[[2.0000e+00 1.7241e+04 1.7241e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 2.5810e+04 3.0000e+00 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 1.6917e+04 2.4347e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " ...\n",
      " [2.0000e+00 1.8058e+04 2.7564e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 1.1655e+04 2.7672e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.0000e+00 1.6917e+04 1.3258e+04 ... 0.0000e+00 0.0000e+00 0.0000e+00]]\n",
      "Decoder Target Batch:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "------------------------------\n",
      "(128, 12) (128, 22) (128, 22, 28304)\n"
     ]
    }
   ],
   "source": [
    "def generate_batch(X, Y, batch_size=128):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_english_sen_len), dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_french_sen_len), dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_french_sen_len, num_decoder_tokens), dtype='float32')\n",
    "            \n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], Y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word]\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t < len(target_text.split()) - 1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word]\n",
    "                    if t > 0:\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            \n",
    "            yield ([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "batch_size = 128\n",
    "train_gen = generate_batch(x_train, y_train, batch_size)\n",
    "num_batches_to_print = 2\n",
    "for batch_num in range(num_batches_to_print):\n",
    "    [encoder_input_batch, decoder_input_batch], decoder_target_batch = next(train_gen)\n",
    "    print(f\"Batch {batch_num + 1}:\")\n",
    "    print(\"Encoder Input Batch:\")\n",
    "    print(encoder_input_batch)\n",
    "    print(\"Decoder Input Batch:\")\n",
    "    print(decoder_input_batch)\n",
    "    print(\"Decoder Target Batch:\")\n",
    "    print(decoder_target_batch)\n",
    "    print(\"-\" * 30)\n",
    "    print(encoder_input_batch.shape,decoder_input_batch.shape,decoder_target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T14:17:17.824292Z",
     "iopub.status.busy": "2023-08-28T14:17:17.823583Z",
     "iopub.status.idle": "2023-08-28T18:27:30.118663Z",
     "shell.execute_reply": "2023-08-28T18:27:30.117462Z",
     "shell.execute_reply.started": "2023-08-28T14:17:17.824255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 12, 100)      1372100     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 12, 100),    80400       ['embedding[0][0]']              \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 12, 100),    80400       ['lstm[0][0]',                   \n",
      "                                 (None, 100),                     'lstm_1[0][0]']                 \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 22, 100)      2830400     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, 22, 100),    80400       ['embedding_1[0][0]',            \n",
      "                                 (None, 100),                     'lstm_1[1][1]',                 \n",
      "                                 (None, 100)]                     'lstm_1[1][2]']                 \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  [(None, 22, 100),    80400       ['lstm_3[0][0]']                 \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " attention_layer (Attention)    (None, 22, 100)      1           ['lstm_5[0][0]',                 \n",
      "                                                                  'lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 22, 200)      0           ['attention_layer[0][0]',        \n",
      "                                                                  'lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 22, 28304)    5689104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,213,205\n",
      "Trainable params: 10,213,205\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 1378s 1s/step - loss: 4.3778 - accuracy: 0.3220 - val_loss: 3.1847 - val_accuracy: 0.4450\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 1364s 1s/step - loss: 2.7796 - accuracy: 0.4817 - val_loss: 2.4397 - val_accuracy: 0.5478\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 1366s 1s/step - loss: 2.2022 - accuracy: 0.5471 - val_loss: 2.1760 - val_accuracy: 0.5875\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 1363s 1s/step - loss: 1.9064 - accuracy: 0.5815 - val_loss: 2.0420 - val_accuracy: 0.6101\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 1364s 1s/step - loss: 1.7229 - accuracy: 0.6053 - val_loss: 1.9726 - val_accuracy: 0.6250\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 1360s 1s/step - loss: 1.6008 - accuracy: 0.6230 - val_loss: 1.9302 - val_accuracy: 0.6347\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 1361s 1s/step - loss: 1.5100 - accuracy: 0.6370 - val_loss: 1.9075 - val_accuracy: 0.6414\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 1362s 1s/step - loss: 1.4447 - accuracy: 0.6476 - val_loss: 1.8867 - val_accuracy: 0.6481\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 1364s 1s/step - loss: 1.3926 - accuracy: 0.6567 - val_loss: 1.8681 - val_accuracy: 0.6531\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 1364s 1s/step - loss: 1.3522 - accuracy: 0.6633 - val_loss: 1.8702 - val_accuracy: 0.6561\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 1361s 1s/step - loss: 1.3158 - accuracy: 0.6695 - val_loss: 1.8600 - val_accuracy: 0.6607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7a9b7068de10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the encoder\n",
    "encoder_inputs = Input(shape=(max_english_sen_len,))\n",
    "encoder_embedding = Embedding(num_encoder_tokens, latent_dimension, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm1 = LSTM(latent_dimension, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "encoder_outputs1, state_h1, state_c1 = encoder_lstm1(encoder_embedding)\n",
    "encoder_lstm2 = LSTM(latent_dimension, return_state=True, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs1)\n",
    "encoder_lstm3 = LSTM(latent_dimension, return_state=True, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm2(encoder_outputs2)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder\n",
    "decoder_inputs = Input(shape=(max_french_sen_len,))\n",
    "decoder_embedding = Embedding(num_decoder_tokens, latent_dimension, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm1 = LSTM(latent_dimension, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "decoder_lstm2 = LSTM(latent_dimension, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "decoder_lstm3 = LSTM(latent_dimension, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "\n",
    "decoder_outputs1, _, _ = decoder_lstm1(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_outputs2, _, _ = decoder_lstm2(decoder_outputs1)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm3(decoder_outputs1)\n",
    "\n",
    "#Attention mechanism\n",
    "attention = Attention(use_scale=True, name='attention_layer')\n",
    "context_vector = attention([decoder_outputs, encoder_outputs])\n",
    "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "# Define the model\n",
    "seq2seq_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "adam_optimizer = Adam(learning_rate = 0.01)\n",
    "# Compile the model\n",
    "seq2seq_model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "seq2seq_model.summary()\n",
    "\n",
    "# Train the model using the data generator\n",
    "batch_size = 128\n",
    "train_gen = generate_batch(x_train, y_train, batch_size)\n",
    "test_gen = generate_batch(x_test, y_test, batch_size)\n",
    "seq2seq_model.fit(train_gen, steps_per_epoch=len(x_train)//batch_size, epochs=50,validation_data = test_gen, validation_steps = len(x_test)//batch_size,callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T18:40:56.822096Z",
     "iopub.status.busy": "2023-08-28T18:40:56.821622Z",
     "iopub.status.idle": "2023-08-28T18:40:56.833428Z",
     "shell.execute_reply": "2023-08-28T18:40:56.832371Z",
     "shell.execute_reply.started": "2023-08-28T18:40:56.822052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191679    i look forward to meeting you again soon\n",
       " 158969           that pair of pliers came in handy\n",
       " 116449                everyone looks uncomfortable\n",
       " 126786               i hope that you get well soon\n",
       " 184501        if i find your passport ill call you\n",
       "                             ...                   \n",
       " 7295                                  dont do that\n",
       " 52809                         we have an advantage\n",
       " 997                                      get going\n",
       " 44732                           we dont understand\n",
       " 112014                 she advised him to exercise\n",
       " Name: eng, Length: 160000, dtype: object,\n",
       " 191679     <SOS> je me réjouis de vous revoir bientôt <EOS>\n",
       " 158969                 <SOS> cette pince savéra utile <EOS>\n",
       " 116449         <SOS> tout le monde a lair mal à laise <EOS>\n",
       " 126786     <SOS> jespère que tu te rétabliras bientôt <EOS>\n",
       " 184501    <SOS> si je trouve votre passeport je vous app...\n",
       "                                 ...                        \n",
       " 7295                           <SOS> ne faites pas ça <EOS>\n",
       " 52809                    <SOS> nous avons un avantage <EOS>\n",
       " 997                                      <SOS> allezy <EOS>\n",
       " 44732                    <SOS> nous ne comprenons pas <EOS>\n",
       " 112014    <SOS> elle lui a conseillé de faire de lexerci...\n",
       " Name: fra, Length: 160000, dtype: object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T18:41:02.990886Z",
     "iopub.status.busy": "2023-08-28T18:41:02.990511Z",
     "iopub.status.idle": "2023-08-28T18:41:03.428700Z",
     "shell.execute_reply": "2023-08-28T18:41:03.427611Z",
     "shell.execute_reply.started": "2023-08-28T18:41:02.990854Z"
    }
   },
   "outputs": [],
   "source": [
    "seq2seq_model.save_weights('/kaggle/working/nmt_weights.h5')\n",
    "seq2seq_model.save('/kaggle/working/nmt.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Translate input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-28T18:43:15.667485Z",
     "iopub.status.busy": "2023-08-28T18:43:15.666363Z",
     "iopub.status.idle": "2023-08-28T18:43:17.391136Z",
     "shell.execute_reply": "2023-08-28T18:43:17.390194Z",
     "shell.execute_reply.started": "2023-08-28T18:43:15.667433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5981, 375, 10220]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "12662\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "24578\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "26288\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "12662\n",
      "Input: i am sad\n",
      "Predicted Translation: je suis triste je suis triste je suis triste je suis triste je suis triste je suis triste je suis triste je\n"
     ]
    }
   ],
   "source": [
    "def translate(input_sentence):\n",
    "    # Preprocess input sentence\n",
    "    input_sentence = input_sentence.lower()\n",
    "    input_sentence = ''.join(char for char in input_sentence if char not in punctuation)\n",
    "    input_sentence = ''.join(char for char in input_sentence if char not in digits)\n",
    "    input_sentence = input_sentence.strip()\n",
    "    input_sentence = re.sub(\" +\", \" \", input_sentence)\n",
    "    \n",
    "    # Tokenize input sentence\n",
    "    input_words = input_sentence.split()\n",
    "    input_indices = [input_token_index.get(word, 0) for word in input_words]\n",
    "    print(input_indices)\n",
    "    # Create encoder input\n",
    "    encoder_input_data = np.zeros((1, max_english_sen_len), dtype='float32')\n",
    "    for t, index in enumerate(input_indices):\n",
    "        encoder_input_data[0, t] = index\n",
    "    \n",
    "    # Initial decoder input\n",
    "    decoder_input_data = np.zeros((1, 1), dtype='float32')\n",
    "    decoder_input_data[0, 0] = target_token_index['<SOS>']\n",
    "    \n",
    "    # Translate using the model\n",
    "    translation = ''\n",
    "    for _ in range(max_french_sen_len):\n",
    "        decoder_output = seq2seq_model.predict([encoder_input_data, decoder_input_data])\n",
    "        predicted_token_index = np.argmax(decoder_output[0, -1, :])\n",
    "        print(predicted_token_index)\n",
    "        predicted_word = reverse_target_char_index.get(predicted_token_index, '<UNK>')\n",
    "        \n",
    "        if predicted_word == '<EOS>':\n",
    "            break\n",
    "        \n",
    "        translation += predicted_word + ' '\n",
    "        \n",
    "        # Update decoder input for next iteration\n",
    "        decoder_input_data = np.zeros((1, 1), dtype='float32')\n",
    "        decoder_input_data[0, 0] = predicted_token_index\n",
    "    \n",
    "    return translation.strip()\n",
    "\n",
    "input_sentence = \"i am sad\"\n",
    "predicted_translation = translate(input_sentence)\n",
    "print(\"Input:\", input_sentence)\n",
    "print(\"Predicted Translation:\", predicted_translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
